{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PROJ_LIB'] = r'C:\\Users\\osori050\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-clone\\Library\\share\\proj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import zipfile\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import math\n",
    "import shutil\n",
    "from scipy.stats import zscore\n",
    "import fiona\n",
    "from fiona.crs import from_epsg\n",
    "from shapely import geometry\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set workspace\n",
    "os.chdir(r'E:\\ArcGIS_2\\Lab4')\n",
    "wksp = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, May 5, 2023 2:46:53 PM\",\"Succeeded at Friday, May 5, 2023 2:46:53 PM (Elapsed Time: 0.86 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'E:\\\\ArcGIS_2\\\\Lab4\\\\cities_projected.shp'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Project cities back to UTM 15N\n",
    "sr = arcpy.SpatialReference(26915)\n",
    "arcpy.Project_management('cities.shp', 'cities_projected.shp', sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cities with stinkbug presence data frame\n",
    "affected_cities = gpd.read_file('sbug_cities.shp')\n",
    "affected_cities.drop(affected_cities.iloc[:, np.r_[0, 2:10]], axis=1, inplace=True) \n",
    "affected_cities['Presence'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All cities data frame\n",
    "cities_gdf = gpd.read_file('cities_projected.shp')\n",
    "cities_gdf.drop(cities_gdf.iloc[:, np.r_[0, 2:6, 7:9]], axis=1, inplace=True) \n",
    "\n",
    "# Add presence to cities data frame\n",
    "cities_gdf = cities_gdf.merge(affected_cities, on='FEATURE_NA', how='left')\n",
    "cities_gdf['Presence'] = cities_gdf['Presence'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read mean min temp shapefile\n",
    "temp = gpd.read_file(\"cities_min_temp.shp\")\n",
    "temp.drop(temp.iloc[:, np.r_[0, 2:9, 10]], axis=1, inplace=True)\n",
    "temp.reset_index(inplace=True)\n",
    "\n",
    "# Join data to cities\n",
    "cities_gdf.reset_index(inplace=True)\n",
    "cities_gdf = cities_gdf.merge(temp, on='index', how='inner')\n",
    "cities_gdf.drop(cities_gdf.iloc[:, np.r_[0, 5]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate z-values for population and temp\n",
    "cols = ['POPULATION', 'min_temp']\n",
    "z_val = cities_gdf[cols].apply(zscore)\n",
    "cities_gdf = cities_gdf.join(z_val, rsuffix=\" (Z)\")\n",
    "\n",
    "# Move the distribution so the starting poing is zero\n",
    "cities_gdf[\"POPULATION (Z)\"] = cities_gdf[\"POPULATION (Z)\"].apply(lambda x: abs(cities_gdf[\"POPULATION (Z)\"].min()) + x)\n",
    "cities_gdf[\"min_temp (Z)\"] = cities_gdf[\"min_temp (Z)\"].apply(lambda x: abs(cities_gdf[\"min_temp (Z)\"].min()) + x)\n",
    "\n",
    "# Only cities with presencce\n",
    "cities_with_presence = cities_gdf[cities_gdf[\"Presence\"] == 1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine each city with presence with the others in MN except with itself\n",
    "combinations = product(cities_with_presence.values, cities_gdf.values)\n",
    "df_combined = pd.DataFrame([*combinations], columns=['From', 'To'])\n",
    "df_combined[['From', 'To']] = df_combined[['From', 'To']].applymap(lambda x: x[0])\n",
    "df_combined = df_combined.loc[df_combined['From'] != df_combined['To']]\n",
    "df_combined.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring back the geometry and other fields to 'From' and 'To' cities\n",
    "df_combined = df_combined.merge(cities_gdf, left_on='From', right_on='FEATURE_NA_x', how='inner')\n",
    "df_combined = df_combined.merge(cities_gdf, left_on='To', right_on='FEATURE_NA_x', how='left')\n",
    "df_combined.drop(df_combined.iloc[:, np.r_[2, 3, 6, 9, 10, 13]], axis=1, inplace=True)\n",
    "df_combined.drop_duplicates(inplace=True) # Remove duplicates generated in the previous join\n",
    "df_combined.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weight\n",
    "df_combined['W From'] = df_combined['POPULATION (Z)_x'] + df_combined['min_temp (Z)_x']\n",
    "df_combined['W To'] = df_combined['POPULATION (Z)_y'] + df_combined['min_temp (Z)_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate centroids\n",
    "df_combined['centroid_from'] = ''\n",
    "df_combined['centroid_to'] = ''\n",
    "for i in range(len(df_combined)):\n",
    "    df_combined.at[i, 'centroid_from'] = df_combined['geometry_x'][i].centroid.coords[0]\n",
    "    df_combined.at[i, 'centroid_to'] = df_combined['geometry_y'][i].centroid.coords[0]\n",
    "    \n",
    "# Calculate euclidean distance\n",
    "df_combined['Distance'] = ''\n",
    "for i in range(len(df_combined)):\n",
    "    df_combined.at[i, 'Distance'] = math.dist(df_combined.at[i, 'centroid_from'], df_combined.at[i, 'centroid_to']) / 1000 # km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unneeded columns\n",
    "df_combined.drop(df_combined.iloc[:, np.r_[2, 4:7, 8, 9, 12, 13]], axis=1, inplace=True)\n",
    "\n",
    "# Rename columns\n",
    "df_combined = df_combined.rename(columns={'Presence_x': 'Presence From', \n",
    "                                            'Presence_y': 'Presence To'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the 3 different models\n",
    "gravity = df_combined.copy()\n",
    "gravity['Force'] = (gravity['W From']*gravity['W To'])/gravity['Distance']\n",
    "\n",
    "huff_simple = df_combined.copy()\n",
    "huff_simple['Force'] = huff_simple['W To']/huff_simple['Distance']\n",
    "\n",
    "huff_faster_decay = df_combined.copy()\n",
    "huff_faster_decay['Force'] = huff_faster_decay['W To']/(huff_faster_decay['Distance']**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling(model):\n",
    "    # Calculate total force for each from-city\n",
    "    force_per_from_city = model.groupby('From').agg({'Force': 'sum'}).reset_index()\n",
    "    force_per_from_city = force_per_from_city.rename(columns={'Force': 'Total force per from-city'})\n",
    "    model = model.merge(force_per_from_city, on='From', how='left')\n",
    "\n",
    "    # Probability of transition\n",
    "    model['Prob_trans'] = 0\n",
    "    for i in range(len(model)):\n",
    "        if model.at[i, 'Total force per from-city'] != 0:\n",
    "            model.at[i, 'Prob_trans'] = model.at[i, 'Force']/model.at[i, 'Total force per from-city']\n",
    "        else:\n",
    "            model.at[i, 'Total force per from-city'] = 0\n",
    "            \n",
    "    # Monte carlo simulation\n",
    "    for i in range (0,100):\n",
    "        # Get draw from flat distribution\n",
    "        transition_draw = np.random.random()\n",
    "\n",
    "        # Predict affected cities\n",
    "        for index, row in model.iterrows():\n",
    "            if row[\"Prob_trans\"] > transition_draw:\n",
    "                model.loc[index, \"Presence To\"] = 1\n",
    "                \n",
    "    # Calculate risk of invasion for each city\n",
    "    risk = model.groupby('To').agg({'Prob_trans': 'sum'}).reset_index()\n",
    "    risk = risk.rename(columns={'Prob_trans': 'Risk'})\n",
    "    \n",
    "    # Extract potential cities affected into a new data frame\n",
    "    predicted = model[model[\"Presence To\"] == 1].copy()\n",
    "    predicted = predicted.groupby('To').agg({'Presence To': 'min'}).reset_index()\n",
    "    \n",
    "    # Read city shapefile again and join the prediction and risk\n",
    "    cities_gdf = gpd.read_file('cities_projected.shp')\n",
    "    cities_gdf.drop(cities_gdf.iloc[:, np.r_[0, 2:9]], axis=1, inplace=True) \n",
    "    cities_gdf = cities_gdf.rename(columns={'FEATURE_NA': 'Name'})\n",
    "    cities_gdf = cities_gdf.merge(predicted, left_on='Name', right_on='To', how='left')\n",
    "    cities_gdf = cities_gdf.merge(risk, left_on='Name', right_on='To', how='left')\n",
    "    cities_gdf.drop(cities_gdf.iloc[:, np.r_[2, 4]], axis=1, inplace=True) \n",
    "    cities_gdf = cities_gdf.rename(columns={'Presence To': 'Presence'})\n",
    "    cities_gdf['Presence'] = cities_gdf['Presence'].fillna(0)\n",
    "    \n",
    "    return cities_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate the models and create geo data frames with the outputs\n",
    "gravity_gdf = modeling(gravity)\n",
    "\n",
    "huff_simple_gdf = modeling(huff_simple)\n",
    "\n",
    "huff_faster_decay_gdf = modeling(huff_faster_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cities predicted with the gravity model: 142\n",
      "Number of cities predicted with the huff simple model: 681\n",
      "Number of cities predicted with the huff model when alpha=2: 186\n"
     ]
    }
   ],
   "source": [
    "gravity_results = gravity_gdf[gravity_gdf[\"Presence\"] == 1].copy()\n",
    "print(f\"Number of cities predicted with the gravity model: {len(gravity_results['Name'].unique())}\")\n",
    "\n",
    "simple_results = huff_simple_gdf[huff_simple_gdf[\"Presence\"] == 1].copy()\n",
    "print(f\"Number of cities predicted with the huff simple model: {len(simple_results['Name'].unique())}\")\n",
    "\n",
    "faster_decay_results = huff_faster_decay_gdf[huff_faster_decay_gdf[\"Presence\"] == 1].copy()\n",
    "print(f\"Number of cities predicted with the huff model when alpha=2: {len(faster_decay_results['Name'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gravity model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output shapefile schema\n",
    "schema = {\n",
    "    'geometry': 'Polygon',\n",
    "    'properties': {\n",
    "        'Name': 'str',\n",
    "        'Presence': 'int',\n",
    "        'Risk': 'float'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Set the CRS of the GeoDataFrame\n",
    "crs = from_epsg(26915)\n",
    "\n",
    "# Open the output shapefile and write the GeoDataFrame to it\n",
    "with fiona.open('cities_results.shp', 'w', driver='ESRI Shapefile', schema=schema, crs=crs) as output:\n",
    "    for index, row in gravity_gdf.iterrows():\n",
    "        output.write({\n",
    "            'geometry': geometry.mapping(row.geometry),\n",
    "            'properties': {\n",
    "                'Name': row['Name'],\n",
    "                'Presence': row['Presence'],\n",
    "                'Risk': row['Risk']\n",
    "            }\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, May 5, 2023 3:09:38 PM\",\"Succeeded at Friday, May 5, 2023 3:09:39 PM (Elapsed Time: 0.99 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'E:\\\\ArcGIS_2\\\\Lab4\\\\cities_results_projected.shp'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-project cities to WGS 1984\n",
    "sr = arcpy.SpatialReference(4326)\n",
    "arcpy.Project_management('cities_results.shp', 'cities_results_projected.shp', sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to postgresql database\n",
    "connection = psycopg2.connect(host = '34.27.219.64',\n",
    "                              port = '5432',\n",
    "                              database = 'lab1',\n",
    "                              user = 'postgres',\n",
    "                              password = 'student',\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\"cities_results_projected.shp\")\n",
    "fields = [\"Name\", \"Presence\", \"Risk\", \"Shape@WKT\"]\n",
    "\n",
    "# Create SQL table\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"DROP TABLE IF EXISTS cities\")\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE cities (\n",
    "        id SERIAL,\n",
    "        Name VARCHAR,\n",
    "        Presence INTEGER,\n",
    "        Risk DOUBLE PRECISION)\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT AddGeometryColumn('cities', 'geom', 4326, 'MULTIPOLYGON', 2)\n",
    "\"\"\")\n",
    "\n",
    "# Populate PostGIS\n",
    "with arcpy.da.SearchCursor(data, fields) as da_cursor:\n",
    "    for row in da_cursor:\n",
    "        wkt = row[3]\n",
    "        cursor.execute(\"INSERT INTO cities (Name, Presence, Risk, geom) VALUES (%s, %s, %s, ST_GeomFromText(%s, 4326))\", (row[0], row[1], row[2], wkt))\n",
    "\n",
    "connection.commit()\n",
    "connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
