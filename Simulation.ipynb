{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PROJ_LIB'] = r'C:\\Users\\osori050\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-clone\\Library\\share\\proj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import zipfile\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import math\n",
    "import shutil\n",
    "from scipy.stats import zscore\n",
    "import fiona\n",
    "from fiona.crs import from_epsg\n",
    "from shapely import geometry\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set workspace\n",
    "os.chdir(r'E:\\ArcGIS_2\\Lab4')\n",
    "wksp = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, May 4, 2023 5:03:18 PM\",\"Succeeded at Thursday, May 4, 2023 5:03:19 PM (Elapsed Time: 1.10 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'E:\\\\ArcGIS_2\\\\Lab4\\\\cities_projected.shp'>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Project cities back to UTM 15N\n",
    "sr = arcpy.SpatialReference(26915)\n",
    "arcpy.Project_management('cities.shp', 'cities_projected.shp', sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cities with stink bug presence data frame\n",
    "affected_cities = gpd.read_file('sbug_cities.shp')\n",
    "affected_cities.drop(affected_cities.iloc[:, np.r_[0, 2:10]], axis=1, inplace=True) \n",
    "affected_cities['Presence'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All cities data frame\n",
    "cities_gdf = gpd.read_file('cities_projected.shp')\n",
    "cities_gdf.drop(cities_gdf.iloc[:, np.r_[0, 2:6, 7:9]], axis=1, inplace=True) \n",
    "\n",
    "# Add presence to cities data frame\n",
    "cities_gdf = cities_gdf.merge(affected_cities, on='FEATURE_NA', how='left')\n",
    "cities_gdf['Presence'] = cities_gdf['Presence'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read mean min temp shapefile\n",
    "temp = gpd.read_file(\"cities_min_temp.shp\")\n",
    "temp.drop(temp.iloc[:, np.r_[0, 2:9, 10]], axis=1, inplace=True)\n",
    "temp.reset_index(inplace=True)\n",
    "\n",
    "# Join data to cities\n",
    "cities_gdf.reset_index(inplace=True)\n",
    "cities_gdf = cities_gdf.merge(temp, on='index', how='inner')\n",
    "cities_gdf.drop(cities_gdf.iloc[:, np.r_[0, 5]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate z-values for population and temp\n",
    "cols = ['POPULATION', 'min_temp']\n",
    "z_val = cities_gdf[cols].apply(zscore)\n",
    "cities_gdf = cities_gdf.join(z_val, rsuffix=\" (Z)\")\n",
    "\n",
    "# Move the distribution so the starting poing is zero\n",
    "cities_gdf[\"POPULATION (Z)\"] = cities_gdf[\"POPULATION (Z)\"].apply(lambda x: abs(cities_gdf[\"POPULATION (Z)\"].min()) + x)\n",
    "cities_gdf[\"min_temp (Z)\"] = cities_gdf[\"min_temp (Z)\"].apply(lambda x: abs(cities_gdf[\"min_temp (Z)\"].min()) + x)\n",
    "\n",
    "# Only cities with presencce\n",
    "cities_with_presence = cities_gdf[cities_gdf[\"Presence\"] == 1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine each city with the others in MN except with itself\n",
    "combinations = product(cities_with_presence.values, cities_gdf.values)\n",
    "df_combined = pd.DataFrame([*combinations], columns=['From', 'To'])\n",
    "df_combined[['From', 'To']] = df_combined[['From', 'To']].applymap(lambda x: x[0])\n",
    "df_combined = df_combined.loc[df_combined['From'] != df_combined['To']]\n",
    "df_combined.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add geometry to 'From' and 'To' cities\n",
    "df_combined = df_combined.merge(cities_gdf, left_on='From', right_on='FEATURE_NA_x', how='inner')\n",
    "df_combined = df_combined.merge(cities_gdf, left_on='To', right_on='FEATURE_NA_x', how='left')\n",
    "df_combined.drop(df_combined.iloc[:, np.r_[2, 3, 6, 9, 10, 13]], axis=1, inplace=True)\n",
    "df_combined.drop_duplicates(inplace=True) # Remove duplicates generated in the previous join\n",
    "df_combined.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weight\n",
    "df_combined['W From'] = df_combined['POPULATION (Z)_x'] + df_combined['min_temp (Z)_x']\n",
    "df_combined['W To'] = df_combined['POPULATION (Z)_y'] + df_combined['min_temp (Z)_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate centroids\n",
    "df_combined['centroid_from'] = ''\n",
    "df_combined['centroid_to'] = ''\n",
    "for i in range(len(df_combined)):\n",
    "    df_combined.at[i, 'centroid_from'] = df_combined['geometry_x'][i].centroid.coords[0]\n",
    "    df_combined.at[i, 'centroid_to'] = df_combined['geometry_y'][i].centroid.coords[0]\n",
    "    \n",
    "# Calculate euclidean distance\n",
    "df_combined['Distance'] = ''\n",
    "for i in range(len(df_combined)):\n",
    "    df_combined.at[i, 'Distance'] = math.dist(df_combined.at[i, 'centroid_from'], df_combined.at[i, 'centroid_to']) / 1000 # km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unneeded columns\n",
    "df_combined.drop(df_combined.iloc[:, np.r_[2, 4:7, 8, 9, 12, 13]], axis=1, inplace=True)\n",
    "\n",
    "# Rename columns\n",
    "df_combined = df_combined.rename(columns={'Presence_x': 'Presence From', \n",
    "                                            'Presence_y': 'Presence To'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the 3 different models\n",
    "gravity = df_combined.copy()\n",
    "gravity['Force'] = (gravity['W From']*gravity['W To'])/gravity['Distance']\n",
    "\n",
    "huff_simple = df_combined.copy()\n",
    "huff_simple['Force'] = huff_simple['W To']/huff_simple['Distance']\n",
    "\n",
    "huff_faster_decay = df_combined.copy()\n",
    "huff_faster_decay['Force'] = huff_faster_decay['W To']/(huff_faster_decay['Distance']**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling(model):\n",
    "    # Calculate total force for each from-city\n",
    "    force_per_from_city = model.groupby('From').agg({'Force': 'sum'}).reset_index()\n",
    "    force_per_from_city = force_per_from_city.rename(columns={'Force': 'Total force per from-city'})\n",
    "    model = model.merge(force_per_from_city, on='From', how='left')\n",
    "\n",
    "    # Probability of transition\n",
    "    model['Prob_trans'] = 0\n",
    "    for i in range(len(model)):\n",
    "        if model.at[i, 'Total force per from-city'] != 0:\n",
    "            model.at[i, 'Prob_trans'] = model.at[i, 'Force']/model.at[i, 'Total force per from-city']\n",
    "        else:\n",
    "            model.at[i, 'Total force per from-city'] = 0\n",
    "            \n",
    "    # Monte carlo simulation\n",
    "    for i in range (0,100):\n",
    "        # Get draw from flat distribution\n",
    "        transition_draw = np.random.random()\n",
    "\n",
    "        # Predict affected cities\n",
    "        for index, row in model.iterrows():\n",
    "            if row[\"Prob_trans\"] > transition_draw:\n",
    "                model.loc[index, \"Presence To\"] = 1\n",
    "                \n",
    "    # Calculate risk of invasion for each city\n",
    "    risk = model.groupby('To').agg({'Prob_trans': 'sum'}).reset_index()\n",
    "    risk = risk.rename(columns={'Prob_trans': 'Risk'})\n",
    "    \n",
    "    # Extract potential cities affected into a new data frame\n",
    "    predicted = model[model[\"Presence To\"] == 1].copy()\n",
    "    predicted = predicted.groupby('To').agg({'Presence To': 'min'}).reset_index()\n",
    "    \n",
    "    # Read city shapefile again and join the prediction and risk\n",
    "    cities_gdf = gpd.read_file('cities_projected.shp')\n",
    "    cities_gdf.drop(cities_gdf.iloc[:, np.r_[0, 2:9]], axis=1, inplace=True) \n",
    "    cities_gdf = cities_gdf.rename(columns={'FEATURE_NA': 'Name'})\n",
    "    cities_gdf = cities_gdf.merge(predicted, left_on='Name', right_on='To', how='left')\n",
    "    cities_gdf = cities_gdf.merge(risk, left_on='Name', right_on='To', how='left')\n",
    "    cities_gdf.drop(cities_gdf.iloc[:, np.r_[2, 4]], axis=1, inplace=True) \n",
    "    cities_gdf = cities_gdf.rename(columns={'Presence To': 'Presence'})\n",
    "    cities_gdf['Presence'] = cities_gdf['Presence'].fillna(0)\n",
    "    \n",
    "    return cities_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate the models and create geo data frames with the outputs\n",
    "gravity_gdf = modeling(gravity)\n",
    "\n",
    "huff_simple_gdf = modeling(huff_simple)\n",
    "\n",
    "huff_faster_decay_gdf = modeling(huff_faster_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cities predicted with the gravity model: 62\n",
      "Number of cities predicted with the huff simple model: 467\n",
      "Number of cities predicted with the huff model when alpha=2: 160\n"
     ]
    }
   ],
   "source": [
    "gravity_results = gravity_gdf[gravity_gdf[\"Presence\"] == 1].copy()\n",
    "print(f\"Number of cities predicted with the gravity model: {len(gravity_results['Name'].unique())}\")\n",
    "\n",
    "simple_results = huff_simple_gdf[huff_simple_gdf[\"Presence\"] == 1].copy()\n",
    "print(f\"Number of cities predicted with the huff simple model: {len(simple_results['Name'].unique())}\")\n",
    "\n",
    "faster_decay_results = huff_faster_decay_gdf[huff_faster_decay_gdf[\"Presence\"] == 1].copy()\n",
    "print(f\"Number of cities predicted with the huff model when alpha=2: {len(faster_decay_results['Name'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>geometry</th>\n",
       "      <th>Presence</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bluffton</td>\n",
       "      <td>POLYGON ((-95.21819 46.45608, -95.23910 46.456...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sartell</td>\n",
       "      <td>MULTIPOLYGON (((-94.26356 45.60481, -94.25788 ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.108466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cambridge</td>\n",
       "      <td>MULTIPOLYGON (((-93.26423 45.57300, -93.25328 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Waseca</td>\n",
       "      <td>MULTIPOLYGON (((-93.54707 44.07307, -93.54201 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La Crescent</td>\n",
       "      <td>MULTIPOLYGON (((-91.33659 43.82339, -91.33646 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>Plainview</td>\n",
       "      <td>POLYGON ((-92.18964 44.17411, -92.17971 44.173...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>Albertville</td>\n",
       "      <td>POLYGON ((-93.63381 45.23803, -93.63405 45.224...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>Storden</td>\n",
       "      <td>POLYGON ((-95.31084 44.04338, -95.31072 44.036...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>Rosemount</td>\n",
       "      <td>POLYGON ((-93.10614 44.77570, -93.09563 44.775...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.145193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>Circle Pines</td>\n",
       "      <td>POLYGON ((-93.14296 45.15304, -93.13770 45.153...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.199266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>903 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name  ...      Risk\n",
       "0        Bluffton  ...  0.000872\n",
       "1         Sartell  ...  0.108466\n",
       "2       Cambridge  ...  0.015013\n",
       "3          Waseca  ...  0.007439\n",
       "4     La Crescent  ...  0.005428\n",
       "..            ...  ...       ...\n",
       "898     Plainview  ...  0.014406\n",
       "899   Albertville  ...  0.017126\n",
       "900       Storden  ...  0.001336\n",
       "901     Rosemount  ...  0.145193\n",
       "902  Circle Pines  ...  0.199266\n",
       "\n",
       "[903 rows x 4 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huff_faster_decay_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Huff alpha=2 for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output shapefile schema\n",
    "schema = {\n",
    "    'geometry': 'Polygon',\n",
    "    'properties': {\n",
    "        'Name': 'str',\n",
    "        'Presence': 'int',\n",
    "        'Risk': 'float'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Set the CRS of the GeoDataFrame\n",
    "crs = from_epsg(26915)\n",
    "\n",
    "# Open the output shapefile and write the GeoDataFrame to it\n",
    "with fiona.open('cities_results.shp', 'w', driver='ESRI Shapefile', schema=schema, crs=crs) as output:\n",
    "    for index, row in huff_faster_decay_gdf.iterrows():\n",
    "        output.write({\n",
    "            'geometry': geometry.mapping(row.geometry),\n",
    "            'properties': {\n",
    "                'Name': row['Name'],\n",
    "                'Presence': row['Presence'],\n",
    "                'Risk': row['Risk']\n",
    "            }\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, May 4, 2023 6:23:26 PM\",\"Succeeded at Thursday, May 4, 2023 6:23:27 PM (Elapsed Time: 1.07 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'E:\\\\ArcGIS_2\\\\Lab4\\\\cities_results_projected.shp'>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-project cities to WGS 1984\n",
    "sr = arcpy.SpatialReference(4326)\n",
    "arcpy.Project_management('cities_results.shp', 'cities_results_projected.shp', sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to postgresql database\n",
    "connection = psycopg2.connect(host = '34.27.219.64',\n",
    "                              port = '5432',\n",
    "                              database = 'lab1',\n",
    "                              user = 'postgres',\n",
    "                              password = 'student',\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\"cities_results_projected.shp\")\n",
    "fields = [\"Name\", \"Presence\", \"Risk\", \"Shape@WKT\"]\n",
    "\n",
    "# Create SQL table\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"DROP TABLE IF EXISTS cities\")\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE cities (\n",
    "        id SERIAL,\n",
    "        Name VARCHAR,\n",
    "        Presence INTEGER,\n",
    "        Risk DOUBLE PRECISION)\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT AddGeometryColumn('cities', 'geom', 4326, 'MULTIPOLYGON', 2)\n",
    "\"\"\")\n",
    "\n",
    "# Populate PostGIS\n",
    "with arcpy.da.SearchCursor(data, fields) as da_cursor:\n",
    "    for row in da_cursor:\n",
    "        wkt = row[3]\n",
    "        cursor.execute(\"INSERT INTO cities (Name, Presence, Risk, geom) VALUES (%s, %s, %s, ST_GeomFromText(%s, 4326))\", (row[0], row[1], row[2], wkt))\n",
    "\n",
    "connection.commit()\n",
    "connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
